import pandas as pd
from sqlalchemy import create_engine
import boto3
from io import StringIO

# ----------------------------
# 1. Paramètres S3
# ----------------------------
bucket_name = "data-lake-ensae-projet-9"
folder = "raw/"

# Liste des fichiers CSV
csv_files = [
    # "olist_customers_dataset.csv",
    # "olist_geolocation_dataset.csv",
    # "olist_order_items_dataset.csv",
    # "olist_order_payments_dataset.csv",
    #olist_order_reviews_dataset.csv",
    # "olist_orders_dataset.csv",
    #olist_products_dataset.csv",
    # "olist_sellers_dataset.csv",
    # "product_category_name_translation.csv"
]

# ----------------------------
# 2. Connexion S3
# ----------------------------
s3 = boto3.client('s3')

# ----------------------------
# 3. Connexion RDS MySQL
# ----------------------------
username = "admin"
password = "groupe1_mously"
host = "database-2.cala4g8gsyma.us-east-1.rds.amazonaws.com"
database = "MA_BASE"  # tu peux mettre un nom pour ta DB si nécessaire

engine = create_engine(f"mysql+pymysql://{username}:{password}@{host}:3306/{database}")

# ----------------------------
# 4. Boucle pour chaque fichier CSV
# ----------------------------
for file in csv_files:
    file_key = folder + file
    print(f" Récupération du fichier {file_key} depuis S3 ...")
    
    csv_obj = s3.get_object(Bucket=bucket_name, Key=file_key)
    body = csv_obj['Body'].read().decode('utf-8')
    df = pd.read_csv(StringIO(body))
    
    table_name = file.replace(".csv", "")
    print(f" Chargement dans la table RDS : {table_name}")
    
    df.to_sql(table_name, engine, if_exists="replace", index=False)

print(" Tous les fichiers ont été chargés dans RDS avec succès !")
